{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63fa5bc-3202-4326-a73f-3535c10c71e7",
   "metadata": {},
   "source": [
    "# Configurar o Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db0c117-562b-4848-a5d8-850f0e54f891",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: s3a://raw/*.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Obter o bucket e ler os arquivos CSV\u001b[39;00m\n\u001b[1;32m      8\u001b[0m bucket \u001b[38;5;241m=\u001b[39m datalake\u001b[38;5;241m.\u001b[39mget_bucket(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m csvDf \u001b[38;5;241m=\u001b[39m \u001b[43mdatalake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csvs_from_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Mostrar os dados\u001b[39;00m\n\u001b[1;32m     12\u001b[0m csvDf\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/minio_datalake/minio_datalake/datalake.py:154\u001b[0m, in \u001b[0;36mMinIOSparkDatalake.read_csvs_from_bucket\u001b[0;34m(self, bucket, delimiter)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03mRead all CSV files from a MinIOBucket and return a combined Spark DataFrame.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03mDataFrame: Combined Spark DataFrame.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m csv_files_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3a://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;241m.\u001b[39mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_files_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: s3a://raw/*.csv."
     ]
    }
   ],
   "source": [
    "from minio_datalake.datalake import MinIOSparkDatalake\n",
    "import minio_datalake.settings as settings\n",
    "\n",
    "# Configuração do Datalake\n",
    "datalake = MinIOSparkDatalake(settings.MINIO_ENDPOINT, settings.MINIO_ACCESS_KEY, settings.MINIO_SECRET_KEY, settings.MINIO_USE_SSL)\n",
    "\n",
    "# Obter o bucket e ler os arquivos CSV\n",
    "bucket = datalake.get_bucket('raw')\n",
    "csvDf = datalake.read_csvs_from_bucket(bucket)\n",
    "\n",
    "# Mostrar os dados\n",
    "csvDf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00365e7a-2794-4652-ad46-30733105621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Settings loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINIO_URL: minio:9000\n",
      "ACCESS_KEY: minioadmin\n",
      "SECRET_KEY: minioadmin\n",
      "RAW_BUCKET: raw\n",
      "STAGE_BUCKET: stage\n"
     ]
    }
   ],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,  # Definir nível de log\n",
    "#     format='%(levelname)s: %(message)s',  # Formato das mensagens de log\n",
    "    #     force=True\n",
    "# )\n",
    "\n",
    "# Importações necessárias\n",
    "from minio_datalake.datalake import MinIOSparkDatalake\n",
    "from minio_datalake import settings as settings\n",
    "\n",
    "# Verifique se as variáveis de ambiente estão configuradas corretamente\n",
    "print(f\"MINIO_URL: {settings.MINIO_ENDPOINT}\")\n",
    "print(f\"ACCESS_KEY: {settings.MINIO_ACCESS_KEY}\")\n",
    "print(f\"SECRET_KEY: {settings.MINIO_SECRET_KEY}\")\n",
    "print(f\"RAW_BUCKET: {settings.RAW_BUCKET}\")\n",
    "print(f\"STAGE_BUCKET: {settings.STAGE_BUCKET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c9c0a-829e-4906-b107-de03b74b16a4",
   "metadata": {},
   "source": [
    "#  Inicializar a classe MinIODatalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e31fda-63d1-4593-8f32-3a198f55f661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.\n",
      "DEBUG: Command to send: A\n",
      "8e7944c6b30f6feed8d4df1b647989e67fedf68a279ceb9d7e455ea8139796d0\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.SparkConf\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.api.java.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.api.python.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.ml.python.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.mllib.api.python.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.resource.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.sql.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.sql.api.python.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "org.apache.spark.sql.hive.*\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: j\n",
      "i\n",
      "rj\n",
      "scala.Tuple2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "SparkConf\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.SparkConf\n",
      "DEBUG: Command to send: i\n",
      "org.apache.spark.SparkConf\n",
      "bTrue\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro0\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.app.name\n",
      "sMinIODatalake\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro1\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.serializer.objectStreamReset\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybfalse\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.serializer.objectStreamReset\n",
      "s100\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro2\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.rdd.compress\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybfalse\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "set\n",
      "sspark.rdd.compress\n",
      "sTrue\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro3\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybtrue\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybtrue\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybtrue\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "get\n",
      "sspark.master\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yslocal[*]\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybtrue\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "get\n",
      "sspark.app.name\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysMinIODatalake\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "contains\n",
      "sspark.home\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybfalse\n",
      "DEBUG: Command to send: c\n",
      "o0\n",
      "getAll\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yto4\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i0\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro5\n",
      "DEBUG: Command to send: c\n",
      "o5\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.rdd.compress\n",
      "DEBUG: Command to send: c\n",
      "o5\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysTrue\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro6\n",
      "DEBUG: Command to send: c\n",
      "o6\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.serializer.objectStreamReset\n",
      "DEBUG: Command to send: c\n",
      "o6\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys100\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro7\n",
      "DEBUG: Command to send: c\n",
      "o7\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.master\n",
      "DEBUG: Command to send: c\n",
      "o7\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yslocal[*]\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i3\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro8\n",
      "DEBUG: Command to send: c\n",
      "o8\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.submit.pyFiles\n",
      "DEBUG: Command to send: c\n",
      "o8\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro9\n",
      "DEBUG: Command to send: c\n",
      "o9\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.app.name\n",
      "DEBUG: Command to send: c\n",
      "o9\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysMinIODatalake\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i5\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro10\n",
      "DEBUG: Command to send: c\n",
      "o10\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.submit.deployMode\n",
      "DEBUG: Command to send: c\n",
      "o10\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysclient\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i6\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro11\n",
      "DEBUG: Command to send: c\n",
      "o11\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.ui.showConsoleProgress\n",
      "DEBUG: Command to send: c\n",
      "o11\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ystrue\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: a\n",
      "g\n",
      "o4\n",
      "i7\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro12\n",
      "DEBUG: Command to send: c\n",
      "o12\n",
      "_1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysspark.app.submitTime\n",
      "DEBUG: Command to send: c\n",
      "o12\n",
      "_2\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys1717849475086\n",
      "DEBUG: Command to send: a\n",
      "e\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi8\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "JavaSparkContext\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.api.java.JavaSparkContext\n",
      "DEBUG: Command to send: i\n",
      "org.apache.spark.api.java.JavaSparkContext\n",
      "ro0\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro13\n",
      "DEBUG: Command to send: c\n",
      "o13\n",
      "sc\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro14\n",
      "DEBUG: Command to send: c\n",
      "o14\n",
      "conf\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro15\n",
      "DEBUG: Command to send: A\n",
      "8e7944c6b30f6feed8d4df1b647989e67fedf68a279ceb9d7e455ea8139796d0\n",
      "\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "PythonAccumulatorV2\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o1\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o2\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: i\n",
      "org.apache.spark.api.python.PythonAccumulatorV2\n",
      "s127.0.0.1\n",
      "i52435\n",
      "s8e7944c6b30f6feed8d4df1b647989e67fedf68a279ceb9d7e455ea8139796d0\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Answer received: !yro16\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o3\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: c\n",
      "o13\n",
      "sc\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Answer received: !yro17\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o5\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: c\n",
      "o17\n",
      "register\n",
      "ro16\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o6\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o7\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o8\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "PythonUtils\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o9\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.api.python.PythonUtils\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.api.python.PythonUtils\n",
      "isEncryptionEnabled\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o10\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.api.python.PythonUtils\n",
      "isEncryptionEnabled\n",
      "ro13\n",
      "e\n",
      "\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o4\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Answer received: !ybfalse\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "PythonUtils\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.api.python.PythonUtils\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.api.python.PythonUtils\n",
      "getPythonAuthSocketTimeout\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.api.python.PythonUtils\n",
      "getPythonAuthSocketTimeout\n",
      "ro13\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yL15\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "PythonUtils\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.api.python.PythonUtils\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.api.python.PythonUtils\n",
      "getSparkBufferSize\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.api.python.PythonUtils\n",
      "getSparkBufferSize\n",
      "ro13\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yi65536\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark.SparkFiles\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.SparkFiles\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.SparkFiles\n",
      "getRootDirectory\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.SparkFiles\n",
      "getRootDirectory\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys/tmp/spark-bf51302e-02fd-49fe-9d06-05f7ae478cc0/userFiles-81ce1339-aa3b-459a-8179-dbe1eb885984\n",
      "DEBUG: Command to send: c\n",
      "o15\n",
      "get\n",
      "sspark.submit.pyFiles\n",
      "s\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark.util\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark.util.Utils\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.util.Utils\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.util.Utils\n",
      "getLocalDir\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "o13\n",
      "sc\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro18\n",
      "DEBUG: Command to send: c\n",
      "o18\n",
      "conf\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro19\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.util.Utils\n",
      "getLocalDir\n",
      "ro19\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys/tmp/spark-bf51302e-02fd-49fe-9d06-05f7ae478cc0\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark.util\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yp\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "org.apache.spark.util.Utils\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.util.Utils\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.util.Utils\n",
      "createTempDir\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.util.Utils\n",
      "createTempDir\n",
      "s/tmp/spark-bf51302e-02fd-49fe-9d06-05f7ae478cc0\n",
      "spyspark\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro20\n",
      "DEBUG: Command to send: c\n",
      "o20\n",
      "getAbsolutePath\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ys/tmp/spark-bf51302e-02fd-49fe-9d06-05f7ae478cc0/pyspark-c68d2add-0884-49e7-8ed9-fa5dbe0e3362\n",
      "DEBUG: Command to send: c\n",
      "o15\n",
      "get\n",
      "sspark.python.profile\n",
      "sfalse\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysfalse\n",
      "DEBUG: Command to send: c\n",
      "o15\n",
      "get\n",
      "sspark.python.profile.memory\n",
      "sfalse\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ysfalse\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "SparkSession\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.sql.SparkSession\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.sql.SparkSession\n",
      "getDefaultSession\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.sql.SparkSession\n",
      "getDefaultSession\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro21\n",
      "DEBUG: Command to send: c\n",
      "o21\n",
      "isDefined\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ybfalse\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "SparkSession\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.sql.SparkSession\n",
      "DEBUG: Command to send: c\n",
      "o13\n",
      "sc\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro22\n",
      "DEBUG: Command to send: i\n",
      "java.util.HashMap\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yao23\n",
      "DEBUG: Command to send: c\n",
      "o23\n",
      "put\n",
      "sspark.app.name\n",
      "sMinIODatalake\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yn\n",
      "DEBUG: Command to send: i\n",
      "org.apache.spark.sql.SparkSession\n",
      "ro22\n",
      "ro23\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yro24\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "SparkSession\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.sql.SparkSession\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.sql.SparkSession\n",
      "setDefaultSession\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.sql.SparkSession\n",
      "setDefaultSession\n",
      "ro24\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: r\n",
      "u\n",
      "SparkSession\n",
      "rj\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ycorg.apache.spark.sql.SparkSession\n",
      "DEBUG: Command to send: r\n",
      "m\n",
      "org.apache.spark.sql.SparkSession\n",
      "setActiveSession\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !ym\n",
      "DEBUG: Command to send: c\n",
      "z:org.apache.spark.sql.SparkSession\n",
      "setActiveSession\n",
      "ro24\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o12\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o14\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o17\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o18\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o19\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o20\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o21\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o23\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n"
     ]
    }
   ],
   "source": [
    "datalake = MinIOSparkDatalake(\n",
    "    endpoint=settings.MINIO_ENDPOINT,\n",
    "    access_key=settings.MINIO_ACCESS_KEY,\n",
    "    secret_key=settings.MINIO_SECRET_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7480a0-5209-4e25-a5ac-b3ac3be95cb0",
   "metadata": {},
   "source": [
    "# Verificar a Existência dos Buckets e Criá-los se Necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d0d978-7aba-433a-a649-4cfc7db28fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting new HTTP connection (1): minio:9000\n",
      "DEBUG: http://minio:9000 \"GET /raw?location= HTTP/1.1\" 200 0\n",
      "DEBUG: http://minio:9000 \"HEAD /raw HTTP/1.1\" 200 0\n",
      "DEBUG: http://minio:9000 \"GET /stage?location= HTTP/1.1\" 200 0\n",
      "DEBUG: http://minio:9000 \"HEAD /stage HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'raw' já existe.\n",
      "Bucket 'stage' já existe.\n"
     ]
    }
   ],
   "source": [
    "# Verificar e criar buckets 'raw' e 'stage' se não existirem\n",
    "raw_bucket = datalake.get_bucket(settings.RAW_BUCKET)\n",
    "if not raw_bucket.exists():\n",
    "    raw_bucket.create()\n",
    "    print(f\"Bucket '{settings.RAW_BUCKET}' criado.\")\n",
    "else:\n",
    "    print(f\"Bucket '{settings.RAW_BUCKET}' já existe.\")\n",
    "\n",
    "stage_bucket = datalake.get_bucket(settings.STAGE_BUCKET)\n",
    "if not stage_bucket.exists():\n",
    "    stage_bucket.create()\n",
    "    print(f\"Bucket '{settings.STAGE_BUCKET}' criado.\")\n",
    "else:\n",
    "    print(f\"Bucket '{settings.STAGE_BUCKET}' já existe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8692c476-0f65-4077-8fc5-bf8a3f0614d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: http://minio:9000 \"GET / HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "stage\n",
      "testbucket\n"
     ]
    }
   ],
   "source": [
    "buckets = datalake.get_client().list_buckets()\n",
    "for bucket in buckets:\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1fdafe-2498-4f97-88ef-466f0b7676a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: http://minio:9000 \"GET /raw?delimiter=%2F&encoding-type=url&list-type=2&max-keys=1000&prefix= HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic-3.zip\n"
     ]
    }
   ],
   "source": [
    "raw_bucket = datalake.get_bucket('raw')\n",
    "for obj in raw_bucket.list_object_names():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6d29c8-6b48-465f-8255-0fc5f0f2eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: http://minio:9000 \"HEAD /raw/titanic-3.zip HTTP/1.1\" 200 0\n",
      "DEBUG: http://minio:9000 \"GET /raw/titanic-3.zip HTTP/1.1\" 200 22502\n",
      "DEBUG: minio_destination_path (bucket_name): raw/titanic-3, file_path (object_name): /tmp/titanic-3/titanic-3.csv, file_name: titanic-3.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid bucket name raw/titanic-3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatalake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_zip_to_datalake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/raw/titanic-3.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_to_bucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/minio_datalake/minio_datalake/datalake.py:89\u001b[0m, in \u001b[0;36mMinIODatalake.extract_zip_to_datalake\u001b[0;34m(self, path, extract_to_bucket)\u001b[0m\n\u001b[1;32m     87\u001b[0m     minio_destination_path \u001b[38;5;241m=\u001b[39m bucket_name \u001b[38;5;28;01mif\u001b[39;00m extract_to_bucket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(object_name)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     88\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminio_destination_path (bucket_name): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminio_destination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, file_path (object_name): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, file_name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminio_destination_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m destination_path\n",
      "File \u001b[0;32m~/minio_datalake/minio_datalake/client.py:58\u001b[0m, in \u001b[0;36mMinIOClient.fput_object\u001b[0;34m(self, bucket_name, object_name, file_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfput_object\u001b[39m(\u001b[38;5;28mself\u001b[39m, bucket_name: \u001b[38;5;28mstr\u001b[39m, object_name: \u001b[38;5;28mstr\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Upload a file to a bucket.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    file_path (str): Path to the file.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/minio/api.py:1050\u001b[0m, in \u001b[0;36mMinio.fput_object\u001b[0;34m(self, bucket_name, object_name, file_path, content_type, metadata, sse, progress, part_size, num_parallel_uploads, tags, retention, legal_hold)\u001b[0m\n\u001b[1;32m   1048\u001b[0m file_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(file_path)\u001b[38;5;241m.\u001b[39mst_size\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_data:\n\u001b[0;32m-> 1050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDictType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpart_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpart_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_parallel_uploads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_uploads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegal_hold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegal_hold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/minio/api.py:1810\u001b[0m, in \u001b[0;36mMinio.put_object\u001b[0;34m(self, bucket_name, object_name, data, length, content_type, metadata, sse, progress, part_size, num_parallel_uploads, tags, retention, legal_hold)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mput_object\u001b[39m(\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1752\u001b[0m     bucket_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     legal_hold: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectWriteResult:\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;124;03m    Uploads data from a stream to an object in a bucket.\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1810\u001b[0m     \u001b[43mcheck_bucket_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_aws_host\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m     check_non_empty_string(object_name)\n\u001b[1;32m   1812\u001b[0m     check_sse(sse)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/minio/helpers.py:239\u001b[0m, in \u001b[0;36mcheck_bucket_name\u001b[0;34m(bucket_name, strict, s3_check)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _OLD_BUCKET_NAME_REGEX\u001b[38;5;241m.\u001b[39mmatch(bucket_name):\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid bucket name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IPV4_REGEX\u001b[38;5;241m.\u001b[39mmatch(bucket_name):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbucket name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must not be formatted \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    243\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas an IP address\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid bucket name raw/titanic-3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Command to send: m\n",
      "d\n",
      "o0\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o12\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n",
      "DEBUG: Command to send: m\n",
      "d\n",
      "o22\n",
      "e\n",
      "\n",
      "DEBUG: Answer received: !yv\n"
     ]
    }
   ],
   "source": [
    "datalake.extract_zip_to_datalake('/raw/titanic-3.zip', extract_to_bucket=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a71978-e0e9-446c-b552-a08bda02a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "extracted_files = os.listdir(destination_path)\n",
    "for file_name in extracted_files:\n",
    "    file_path = os.path.join(destination_path, file_name)\n",
    "    minio_destination_path = bucket_name if extract_to_bucket else f'{bucket_name}/{os.path.splitext(object_name)[0]}'\n",
    "    logger.debug(f'minio_destination_path (bucket_name): {minio_destination_path}, file_path (object_name): {file_path}, file_name: {file_name}')\n",
    "    self._client.fput_object(minio_destination_path, file_name, file_path)\n",
    "\n",
    "return destination_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b2e5ba-6d6d-4937-b9fa-d200982a83d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/raw/tmp/titanic-3/titanic-3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m destination_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raw/tmp/titanic-3/titanic-3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/raw/tmp/titanic-3/titanic-3.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "destination_path = '/raw/tmp/titanic-3/titanic-3.csv'\n",
    "os.listdir(destination_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
